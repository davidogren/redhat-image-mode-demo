{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"\ud83c\udfd7\ufe0f\ud83c\udfd7\ufe0f RHEL Image Mode Demo use cases \ud83c\udfd7\ufe0f\ud83c\udfd7\ufe0f","text":"<p>Welcome to this demo content for Red Hat Enterprise Linux Image mode! This content provides a quick way to know more and try out the Image Mode for RHEL, with many use cases that can be easily reproduced in your environment.</p> <p>Below you can find some external resources from Red Hat websites and upstream projects on the topic.</p> <p> Get Started!</p>"},{"location":"#rhel-image-mode","title":"RHEL Image mode","text":"<ul> <li>RHEL Image Mode landing page on Red Hat Website</li> <li>RHEL Image Mode quickstart on Red Hat Blog</li> <li>RHEL Image Mode documentation on Red Hat Website</li> <li>Red Hat Developers - Getting Started with RHEL Image Mode</li> </ul>"},{"location":"#bootc-upstream-projects","title":"bootc Upstream projects","text":"<ul> <li>bootc project on GitHub</li> <li>bootc-image-builder project on GitHub</li> </ul>"},{"location":"getting-started/introduction/","title":"Introducing RHEL Image mode","text":""},{"location":"getting-started/introduction/#what-is-rhel-image-mode","title":"What is RHEL Image Mode?","text":"<p>RHEL Image mode is a new approach for operating system deployment that enables users to create, deploy and manage Red Hat Enterprise Linux as a bootc container image.</p> <p>This approach simplifies operations across the enterprise, allowing developers, operations teams and solution providers to use the same container-native tools and techniques to manage everything from applications to the underlying OS.</p>"},{"location":"getting-started/introduction/#how-is-rhel-image-mode-different","title":"How is RHEL Image Mode different?","text":"<p>Due to the container-oriented nature, RHEL Image mode opens up to a unification and standardization of OS management and deployment, allowing the integration with existing CI/CD workflows and/or GitOps, reducing complexity.</p> <p>RHEL Image mode also helps increasing security as the content, updates and patches are predictable and atomic, preventing manual modification of core services, packages and applications for a guaranteed consistency at scale.</p>"},{"location":"getting-started/quickstart/","title":"\ud83c\udfaf\ud83c\udfaf Let's get started \ud83c\udfaf\ud83c\udfaf","text":"<p>First of all, clone the repo:</p> <pre><code>git clone https://github.com/redhat-cop/redhat-image-mode-demo\n</code></pre> <p>Creating a container for RHEL Image Mode is as easy as writing and running a Containerfile like this:</p> <p>Warning</p> <p>To build images using RHEL bootc image you need a RHEL System with a valid subscription attached to it. For non-production workloads, you can register for a free Red Hat developer subscription.</p> <pre><code>FROM registry.redhat.io/rhel9/rhel-bootc:9.4\n</code></pre> <p>You can proceed customizing the image, adding users, packages, configurations, etc following the Dockerfile Reference as well as providing informative/documentation layers (MAINTAINER, LABEL, etc) following the best-practices of Containerfile creation.</p> <p>Tip</p> <p>Some Dockerfile Directives (EXPOSE, ENTRYPOINT, ENV, among them) are ignored during RHEL Image deployment on a system, see the documentation for more details.</p>"},{"location":"use-cases/bootc-container-anaconda-ks/","title":"Use Case - RHEL Bootc container as a setup source for Kickstart/Anaconda","text":"<p>In this example, we will expand the image we built in the Apache bootc use case that you can use as a reference for details. This way, we will be able to streamline the creation of VMs based on a frozen, immutable configuration that will take few seconds to be deployed.</p> <p>The Containerfile in the example:</p> <ul> <li>Updates packages</li> <li>Installs tmux and mkpasswd to create a simple user password</li> <li>Creates a bootc-user user in the image</li> <li>Adds the wheel group to sudoers</li> <li>Installs Apache Server</li> <li>Enables the systemd unit for httpd</li> <li>Adds a custom index.html</li> <li>Customizes the Message of the day</li> </ul>"},{"location":"use-cases/bootc-container-anaconda-ks/#pre-requisites","title":"Pre-requisites","text":"<p>You need a Container registry to push the image and make it available. I suggest creating an account on Quay.io. During the configuration I will be using my username, kubealex, for the demo.</p>"},{"location":"use-cases/bootc-container-anaconda-ks/#building-the-image","title":"Building the image","text":"<p>You can build the image right from the Containerfile using Podman:</p> <pre><code>podman build -f Containerfile.anaconda -t rhel-bootc-vm:httpd .\n</code></pre>"},{"location":"use-cases/bootc-container-anaconda-ks/#tagging-and-pushing-the-image","title":"Tagging and pushing the image","text":"<p>To tag and push the image you can simply run (replace YOURQUAYUSERNAME with the account name):</p> <pre><code>export QUAY_USER=YOURQUAYUSERNAME\n</code></pre> <pre><code>podman tag rhel-bootc-vm:httpd quay.io/$QUAY_USER/rhel-bootc-vm:httpd\n</code></pre> <p>Log-in to Quay.io:</p> <pre><code>podman login -u $QUAY_USER quay.io\n</code></pre> <p>And push the image:</p> <pre><code>podman push quay.io/$QUAY_USER/rhel-bootc-vm:httpd\n</code></pre> <p>You can now browse to https://quay.io/repository/YOURQUAYUSERNAME/rhel-bootc-httpd?tab=settings and ensure that the repository is set to \"Public\".</p> <p></p>"},{"location":"use-cases/bootc-container-anaconda-ks/#install-rhel-94-using-the-resulting-image","title":"Install RHEL 9.4 using the resulting image","text":""},{"location":"use-cases/bootc-container-anaconda-ks/#prepare-install-media-and-review-the-kickstart-file","title":"Prepare install media and review the kickstart file","text":"<p>RHEL 9.4 are available on the Red Hat Developer portal and for this use case we will only need the boot image.</p> <p>Save the image and place it in the use case folder with the name rhel9.iso</p> <p>The kickstart file is a very simple one:</p> <ul> <li>Configures text install</li> <li>Creates a root user with password redhat</li> <li>Sets up basic partitioning</li> </ul> <p>What is relevant is the ostreecontainer directive, that references the container image we just built as a source for the installation!</p>"},{"location":"use-cases/bootc-container-anaconda-ks/#creating-the-virtual-machine-in-kvm","title":"Creating the Virtual Machine in KVM","text":"<p>You are now ready to spin-up a Virtual Machine using the downloaded boot image for CentOS Stream 9, injecting and using the kickstart to perform an unattended installation.</p> <pre><code>virt-install --name rhel9-server \\\n--memory 4096 \\\n--vcpus 2 \\\n--disk size=20 \\\n--network network=default \\\n--location ./rhel9.iso \\\n--os-variant rhel9.4 \\\n--initrd-inject ks.cfg \\\n--extra-args \"inst.ks=file:/ks.cfg\"\n</code></pre> <p>In a few seconds, the VM will boot and start the installation, grabbing the container image as a source to perform the configuration:</p> <p></p> <p>Based on the connection, it can take a while to fetch the container image and complete the setup. Once it is completed, you can log-in with the bootc-user/redhat credentials, and you will see the custom Message Of The Day (MOTD) we added in our Containerfile!</p> <p></p>"},{"location":"use-cases/bootc-container-httpd/","title":"Use Case - Running a bootc container providing Apache HTTP server","text":"<p>In this example, we will build a container image from a Containerfile and we will then use it as a source for a VM.</p> <p>The Containerfile in the example:</p> <ul> <li>Updates packages</li> <li>Installs tmux and mkpasswd to create a simple user password</li> <li>Creates a bootc-user user in the image</li> <li>Adds the wheel group to sudoers</li> <li>Installs Apache Server</li> <li>Enables the systemd unit for httpd</li> <li>Adds a custom index.html</li> </ul>"},{"location":"use-cases/bootc-container-httpd/#building-the-image","title":"Building the image","text":"<p>Review the Containerfile.httpd file, that includes all the building steps for the image.</p> <p>To build the image:</p> <pre><code>podman build -f Containerfile.httpd -t rhel-bootc-httpd .\n</code></pre>"},{"location":"use-cases/bootc-container-httpd/#testing-the-image","title":"Testing the image","text":"<p>You can now test it using:</p> <pre><code>podman run -it --name rhel-bootc-httpd --hostname rhel-bootc-httpd -p 8080:80 rhel-bootc-httpd\n</code></pre> <p>Note: The \"-p 8080:80\" part forwards the container's http port to the port 8080 on the host to test that it is working.</p> <p>The container will now start and a login prompt will appear:</p> <p></p> <p>On another terminal tab or in your browser, you can verify that the httpd server is working and serving traffic.</p> <p>Terminal</p> <pre><code> ~ \u2593\u2592\u2591 curl localhost:8080\nWelcome to the bootc-http instance!\n</code></pre> <p>Browser</p> <p></p>"},{"location":"use-cases/bootc-container-httpd/#exploring-the-container","title":"Exploring the container","text":"<p>If you are curious, you can easily log-in to the container using the prompt coming from the execution and the bootc-user/redhat user and password.</p> <p>From here, you can verify that:</p> <ul> <li>The user has sudo privileges</li> </ul> <pre><code>[bootc-user@rhel-bootc-bootc ~]$ sudo su\nbash-5.1# whoami\nroot\n</code></pre> <ul> <li>There's systemd running</li> </ul> <pre><code>bash-5.1# systemctl status | more\n\u25cf rhel-bootc-httpd\n    State: running\n    Units: 234 loaded (incl. loaded aliases)\n     Jobs: 0 queued\n   Failed: 0 units\n    Since: Fri 2024-07-19 08:19:28 UTC; 1min 57s ago\n  systemd: 252-32.el9_4\n</code></pre> <ul> <li>Apache is loaded as a systemd unit</li> </ul> <pre><code>bash-5.1# systemctl status httpd\n\u25cf httpd.service - The Apache HTTP Server\n     Loaded: loaded (/usr/lib/systemd/system/httpd.service; enabled; preset: disabled)\n     Active: active (running) since Fri 2024-07-19 08:19:29 UTC; 2min 28s ago\n       Docs: man:httpd.service(8)\n   Main PID: 90 (httpd)\n     Status: \"Total requests: 1; Idle/Busy workers 100/0;Requests/sec: 0.00719; Bytes served/sec:   2 B/sec\"\n      Tasks: 177 (limit: 1638)\n     Memory: 22.0M\n        CPU: 159ms\n     CGroup: /system.slice/httpd.service\n             \u251c\u2500 90 /usr/sbin/httpd -DFOREGROUND\n             \u251c\u2500115 /usr/sbin/httpd -DFOREGROUND\n             \u251c\u2500117 /usr/sbin/httpd -DFOREGROUND\n             \u251c\u2500118 /usr/sbin/httpd -DFOREGROUND\n             \u2514\u2500119 /usr/sbin/httpd -DFOREGROUND\n</code></pre>"},{"location":"use-cases/bootc-container-replace/","title":"Use Case - Applying a different RHEL container image to an existing VM","text":"<p>Our team is looking to improve performances and test different configurations. We created our new and shiny image with Apache HTTPD and MariaDB, but you are exploring alternatives and want to use Nginx and PostgreSQL as some of your team members are more familiar with that stack.</p> <p>We will then create an alternative image, with a dedicated tag, that will help our fellow colleagues in their efforts. Instead of redeploying the VM from scratch, we are going to use bootc to change the reference of the image in our existing VM to use it for configuring the system!</p> <p>The Containerfile will be very close to the previous one:</p> <ul> <li>Updates packages</li> <li>Installs tmux and mkpasswd to create a simple user password</li> <li>Creates a bootc-user user in the image</li> <li>Adds the wheel group to sudoers</li> <li>Installs nginx server</li> <li>Enables the systemd unit for nginx</li> <li>Adds a custom index.html</li> <li>Customizes the Message of the day</li> <li>Add an additional message of the day with the new release notes</li> <li>Add postgresql-server package and vim</li> <li>Enable the postgresql-server systemd unit</li> </ul> <p>Since the bootc switch command will preserve the /var and /etc content, we will use a workaround to create the needed dirs for Nginx and Postgresql leveraging systemd-tmpfiles and systemd-sysusers to ensure users are in place.</p>"},{"location":"use-cases/bootc-container-replace/#building-the-image","title":"Building the image","text":"<p>You can build the image right from the Containerfile using Podman:</p> <pre><code>podman build -f Containerfile.replace -t rhel-bootc-vm:nginx .\n</code></pre>"},{"location":"use-cases/bootc-container-replace/#testing-the-image","title":"Testing the image","text":"<p>You can now test it using:</p> <pre><code>podman run -it --name rhel-bootc-vm-nginx --hostname rhel-bootc-vm-nginx -p 8080:80 -p 5432:5432 rhel-bootc-vm:nginx\n</code></pre> <p>Note: The \"-p 8080:80\" -p 5432:5432 part forwards the container's http and postgresql port to the port 8080 and 3306 on the host to test that nginx and postgresql are working.</p> <p>The container will now start and a login prompt will appear:</p> <p></p>"},{"location":"use-cases/bootc-container-replace/#testing-nginx","title":"Testing Nginx","text":"<p>On another terminal tab or in your browser, you can verify that the httpd server is working and serving traffic.</p> <p>Terminal</p> <pre><code> ~ \u2593\u2592\u2591 curl localhost:8080                                                                                                           \u2591\u2592\u2593 \u2714  11:59:44\nWelcome to the bootc-nginx instance!\n</code></pre> <p>Browser</p> <p></p>"},{"location":"use-cases/bootc-container-replace/#testing-postgresql","title":"Testing Postgresql","text":"<p>From the login prompt, login as bootc-user/redhat and impersonate the root user:</p> <pre><code>[bootc-user@rhel-bootc-vm-nginx ~]$ sudo -i\n[root@rhel-bootc-vm-nginx ~]#\n</code></pre> <p>Initialize PostgreSQL db and config:</p> <pre><code>[root@rhel-bootc-vm-nginx ~]# postgresql-setup --initdb\n * Initializing database in '/var/lib/pgsql/data'\n * Initialized, logs are in /var/lib/pgsql/initdb_postgresql.log\n</code></pre> <p>You will now be able to restart the postgresql systemd unit and test the connection:</p> <pre><code>[root@rhel-bootc-vm-nginx ~]# systemctl restart postgresql\n[root@rhel-bootc-vm-nginx ~]# su - postgres\n[postgres@rhel-bootc-vm-nginx ~]$ psql\npsql (13.14)\nType \"help\" for help.\n\npostgres=#\n</code></pre>"},{"location":"use-cases/bootc-container-replace/#tagging-and-pushing-the-image","title":"Tagging and pushing the image","text":"<p>To tag and push the image you can simply run (replace YOURQUAYUSERNAME with the account name):</p> <pre><code>export QUAY_USER=YOURQUAYUSERNAME\n</code></pre> <pre><code>podman tag rhel-bootc-vm:nginx quay.io/$QUAY_USER/rhel-bootc-vm:nginx\n</code></pre> <p>Log-in to Quay.io:</p> <pre><code>podman login -u $QUAY_USER quay.io\n</code></pre> <p>And push the image:</p> <pre><code>podman push quay.io/$QUAY_USER/rhel-bootc-vm:nginx\n</code></pre> <p>You can now browse to https://quay.io/repository/YOURQUAYUSERNAME/rhel-bootc-httpd?tab=settings and ensure that the repository is set to \"Public\".</p> <p></p>"},{"location":"use-cases/bootc-container-replace/#updating-the-vm-with-the-newly-created-image","title":"Updating the VM with the newly created image","text":"<p>The first thing to do is logging in the VM updated in the previous use case:</p> <pre><code> ~ \u2593\u2592\u2591 ssh bootc-user@192.168.124.16\nbootc-user@192.168.124.16's password: \nThis is a RHEL VM installed using a bootable container as an rpm-ostree source!\nThis server now supports MariaDB as a database, after last update\nLast login: Mon Jul 29 12:12:51 2024 from 192.168.124.1\n[bootc-user@localhost ~]$\n</code></pre> <p>Verify that bootc is installed:</p> <pre><code>[bootc-user@localhost ~]$ bootc --help\nDeploy and transactionally in-place with bootable container images.\n\nThe `bootc` project currently uses ostree-containers as a backend to support a model of bootable container images.  Once installed, whether directly via `bootc install` (executed as part of a container) or via another mechanism such as an OS installer tool, further updates can be pulled via e.g. `bootc upgrade`.\n\nChanges in `/etc` and `/var` persist.\n\nUsage: bootc &lt;COMMAND&gt;\n\nCommands:\n  upgrade      Download and queue an updated container image to apply\n  switch       Target a new container image reference to boot\n  edit         Apply full changes to the host specification\n  status       Display status\n  usr-overlay  Add a transient writable overlayfs on `/usr` that will be discarded on reboot\n  install      Install the running container to a target\n  help         Print this message or the help of the given subcommand(s)\n\nOptions:\n  -h, --help   Print help (see a summary with '-h')\n</code></pre> <p>Note that among the options we have the switch option that we will be using in this use case. The switch option allows checking, fetching and using a different container image to replace the current configuration and spin up a new rpm-ostree image for the system.</p> <p>In our case we will switch from rhel-bootc-vm:httpd to rhel-bootc-vm:nginx image.</p> <p>The switch command requires higher privileges to run, let's perform the change!</p> <pre><code>[bootc-user@localhost ~]$ sudo bootc switch quay.io/kubealex/rhel-bootc-vm:nginx\nlayers already present: 69; layers needed: 7 (182.7 MB)\n 426 B [\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588] (0s) Fetched layer sha256:8a192c7a518d                                                                                                                                                                                                                                                                                                                                            Queued for next boot: quay.io/kubealex/rhel-bootc-vm:nginx\n  Version: 9.20240714.0\n  Digest: sha256:e9dc2975eea3510044934fde745c296b734e8ca6f76add0e92c350e73db54620\n</code></pre> <p>In this case, unlike last time, the layers to retrieve were many more, as we changed big parts of the previous image. At the end of the process, it queued the actual switch after reboot. Let's verify that postgres and nginx are still not present at this time, and proceed with a reboot:</p> <pre><code>[bootc-user@localhost ~]$ systemctl status nginx postgresql\nUnit nginx.service could not be found.\nUnit postgresql.service could not be found.\n[bootc-user@localhost ~]$ sudo reboot\n</code></pre> <p>Let's log back in!</p> <pre><code> ~/\u2593\u2592\u2591 ssh bootc-user@192.168.124.16\nbootc-user@192.168.124.16's password: \nThis is a RHEL 9 VM installed using a bootable container as an rpm-ostree source!\nThis server is equipped with Nginx and PostgreSQL\nLast login: Mon Jul 29 12:26:13 2024 from 192.168.124.1\n</code></pre> <p>You can already see that something changed, we have a different line in our message of the day, let's test if nginx and Postgresql are running and working!</p> <p>Initialize the DB:</p> <pre><code>[root@rhel-bootc-vm-nginx ~]# postgresql-setup --initdb\n * Initializing database in '/var/lib/pgsql/data'\n * Initialized, logs are in /var/lib/pgsql/initdb_postgresql.log\n</code></pre> <p>Restart the PGSQL service:</p> <pre><code>[root@rhel-bootc-vm-nginx ~]# systemctl restart postgresql\n</code></pre> <p>And verify everything is up and running:</p> <pre><code>[bootc-user@localhost ~]$ systemctl status nginx postgresql\n</code></pre> <pre><code>\u25cf nginx.service - The nginx HTTP and reverse proxy server\n     Loaded: loaded (/usr/lib/systemd/system/nginx.service; enabled; preset: disabled)\n     Active: active (running) since Mon 2024-07-29 12:31:03 CEST; 8min ago\n    Process: 727 ExecStartPre=/usr/bin/rm -f /run/nginx.pid (code=exited, status=0/SUCCESS)\n    Process: 730 ExecStartPre=/usr/sbin/nginx -t (code=exited, status=0/SUCCESS)\n    Process: 736 ExecStart=/usr/sbin/nginx (code=exited, status=0/SUCCESS)\n   Main PID: 749 (nginx)\n      Tasks: 3 (limit: 23136)\n     Memory: 4.2M\n        CPU: 11ms\n     CGroup: /system.slice/nginx.service\n             \u251c\u2500749 \"nginx: master process /usr/sbin/nginx\"\n             \u251c\u2500750 \"nginx: worker process\"\n             \u2514\u2500751 \"nginx: worker process\"\n\nJul 29 12:31:03 localhost.localdomain systemd[1]: Starting The nginx HTTP and reverse proxy server...\nJul 29 12:31:03 localhost.localdomain nginx[730]: nginx: the configuration file /etc/nginx/nginx.conf syntax is ok\nJul 29 12:31:03 localhost.localdomain nginx[730]: nginx: configuration file /etc/nginx/nginx.conf test is successful\nJul 29 12:31:03 localhost.localdomain systemd[1]: Started The nginx HTTP and reverse proxy server.\n\n\u25cf postgresql.service - PostgreSQL database server\n     Loaded: loaded (/usr/lib/systemd/system/postgresql.service; enabled; preset: disabled)\n     Active: active (running) since Mon 2024-07-29 12:39:52 CEST; 2s ago\n    Process: 1338 ExecStartPre=/usr/libexec/postgresql-check-db-dir postgresql (code=exited, status=0/SUCCESS)\n   Main PID: 1340 (postmaster)\n      Tasks: 8 (limit: 23136)\n     Memory: 16.5M\n        CPU: 16ms\n     CGroup: /system.slice/postgresql.service\n             \u251c\u25001340 /usr/bin/postmaster -D /var/lib/pgsql/data\n             \u251c\u25001341 \"postgres: logger \"\n             \u251c\u25001343 \"postgres: checkpointer \"\n             \u251c\u25001344 \"postgres: background writer \"\n             \u251c\u25001345 \"postgres: walwriter \"\n             \u251c\u25001346 \"postgres: autovacuum launcher \"\n             \u251c\u25001347 \"postgres: stats collector \"\n             \u2514\u25001348 \"postgres: logical replication launcher \"\n\nJul 29 12:39:52 localhost.localdomain systemd[1]: Starting PostgreSQL database server...\nJul 29 12:39:52 localhost.localdomain postmaster[1340]: 2024-07-29 12:39:52.234 CEST [1340] LOG:  redirecting log output to logging collector process\nJul 29 12:39:52 localhost.localdomain postmaster[1340]: 2024-07-29 12:39:52.234 CEST [1340] HINT:  Future log output will appear in directory \"log\".\nJul 29 12:39:52 localhost.localdomain systemd[1]: Started PostgreSQL database server.\n</code></pre> <p>Let's test if postgresql is working.</p> <pre><code>[bootc-user@localhost ~]$ sudo su -l postgres\nLast login: Mon Mar 18 10:34:34 CET 2024 on pts/0\n[postgres@localhost ~]$ psql\npsql (13.14)\nType \"help\" for help.\n\npostgres=#\n</code></pre> <p>Now we can try and see if the nginx server is reachable, using our browser we can go to the VM IP on port 80 to check:</p> <p></p> <p>Here we go, our VM is fully working. Of course we can use the new image to provision similar VMs that need the same pieces of software on them.</p>"},{"location":"use-cases/bootc-container-simple/","title":"Use Case - Simple RHEL bootc container","text":"<p>This example shows a very simple example of a bootc container the is built starting from a rhel-bootc image.</p> <p>The Containerfile in the example:</p> <ul> <li>Updates packages</li> <li>Installs tmux and mkpasswd to create a simple user password</li> <li>Creates a bootc-user user in the image</li> <li>Adds the wheel group to sudoers</li> </ul> <p>To build the image:</p> <pre><code>podman build -f Containerfile.simple -t rhel-bootc-simple .\n</code></pre> <p>You can now run it using:</p> <pre><code>podman run -it --name bootc-container --hostname bootc-container -p 2022:22 rhel-bootc-simple\n</code></pre> <p>Note: The \"-p 2022:22\" part forwards the container's SSH port to the host 2022 port.</p> <p>The container will now start and a login prompt will appear:</p> <p></p> <p>You can simply login with bootc-user/redhat and play around with the container content!</p>"},{"location":"use-cases/bootc-container-simple/#example-containerfile","title":"Example Containerfile","text":"<pre><code>FROM registry.redhat.io/rhel9/rhel-bootc:9.4\nRUN dnf -y update &amp;&amp; dnf -y install tmux mkpasswd\nRUN pass=$(mkpasswd --method=SHA-512 --rounds=4096 redhat) &amp;&amp; useradd -m -G wheel bootc-user -p $pass\nRUN echo \"%wheel        ALL=(ALL)       NOPASSWD: ALL\" &gt; /etc/sudoers.d/wheel-sudo\nCMD [ \"/sbin/init\" ]\n</code></pre>"},{"location":"use-cases/bootc-container-upgrade/","title":"Use Case - Upgrading a VM based on a bootc image","text":"<p>In this example, we want to add some bits to the previously generated httpd image to add a MariaDB server and a text editor, VIM.</p> <p>We will then use bootc to manage the system update, and you will see how easy and fast perfoming upgrades is.</p> <p>The Containerfile will:</p> <ul> <li>Updates packages</li> <li>Installs tmux and mkpasswd to create a simple user password</li> <li>Creates a bootc-user user in the image</li> <li>Adds the wheel group to sudoers</li> <li>Installs Apache Server</li> <li>Enables the systemd unit for httpd</li> <li>Adds a custom index.html</li> <li>Customizes the Message of the day</li> </ul> <p>But it will add the following two steps, resulting in a different image with an additional layer:</p> <p>- Add an additional message of the day with the upgrade notes - Add mariadb-server package and vim - Enable the mariadb systemd unit</p> <p>Since the bootc update command will preserve the /var and /etc content, we will use a workaround to create the needed dirs for MariaDB leveraging systemd-tmpfiles.</p>"},{"location":"use-cases/bootc-container-upgrade/#building-the-image","title":"Building the image","text":"<p>You can build the image right from the Containerfile using Podman:</p> <pre><code>podman build -f Containerfile.upgrade -t rhel-bootc-vm:httpd .\n</code></pre>"},{"location":"use-cases/bootc-container-upgrade/#testing-the-image","title":"Testing the image","text":"<p>You can now test it using:</p> <pre><code>podman run -it --name rhel-bootc-vm --hostname rhel-bootc-vm -p 8080:80 -p 3306:3306 rhel-bootc-vm:httpd\n</code></pre> <p>Note: The \"-p 8080:80\" -p 3306:3306 part forwards the container's http and mariadb port to the port 8080 and 3306 on the host to test that httpd and mariadb are working.</p> <p>The container will now start and a login prompt will appear:</p> <p></p>"},{"location":"use-cases/bootc-container-upgrade/#testing-apache","title":"Testing Apache","text":"<p>On another terminal tab or in your browser, you can verify that the httpd server is working and serving traffic.</p> <p>Terminal</p> <pre><code> ~ \u2593\u2592\u2591 curl localhost:8080                                                                                                           \u2591\u2592\u2593 \u2714  11:59:44\nWelcome to the bootc-http instance!\n</code></pre> <p>Browser</p> <p></p>"},{"location":"use-cases/bootc-container-upgrade/#testing-mariadb","title":"Testing Mariadb","text":"<p>From the login prompt, login as bootc-user/redhat and impersonate the root user:</p> <pre><code>[bootc-user@rhel-bootc-vm ~]$ sudo -i\n[root@rhel-bootc-vm ~]#\n</code></pre> <p>Verify that mariadb is running:</p> <pre><code>mysql\n</code></pre>"},{"location":"use-cases/bootc-container-upgrade/#tagging-and-pushing-the-image","title":"Tagging and pushing the image","text":"<p>To tag and push the image you can simply run (replace YOURQUAYUSERNAME with the account name):</p> <pre><code>export QUAY_USER=YOURQUAYUSERNAME\n</code></pre> <pre><code>podman tag rhel-bootc-vm:httpd quay.io/$QUAY_USER/rhel-bootc-vm:httpd\n</code></pre> <p>Log-in to Quay.io:</p> <pre><code>podman login -u $QUAY_USER quay.io\n</code></pre> <p>And push the image:</p> <pre><code>podman push quay.io/$QUAY_USER/rhel-bootc-vm:httpd\n</code></pre> <p>You can now browse to https://quay.io/repository/YOURQUAYUSERNAME/rhel-bootc-httpd?tab=settings and ensure that the repository is set to \"Public\".</p> <p></p>"},{"location":"use-cases/bootc-container-upgrade/#updating-the-vm-with-the-newly-created-image","title":"Updating the VM with the newly created image","text":"<p>The first thing to do is logging in the VM created in the previous use case or any other use case (QCOW, ISO, AMI):</p> <pre><code> ~ \u2593\u2592\u2591 ssh bootc-user@192.168.124.16\nbootc-user@192.168.124.16's password: \nThis is a RHEL 9.4 VM installed using a bootable container as an rpm-ostree source!\nLast login: Mon Jul 29 12:03:40 2024 from 192.168.124.1\n[bootc-user@localhost ~]$\n</code></pre> <p>Verify that bootc is installed:</p> <pre><code>[bootc-user@localhost ~]$ bootc --help\nDeploy and transactionally in-place with bootable container images.\n\nThe `bootc` project currently uses ostree-containers as a backend to support a model of bootable container images.  Once installed, whether directly via `bootc install` (executed as part of a container) or via another mechanism such as an OS installer tool, further updates can be pulled via e.g. `bootc upgrade`.\n\nChanges in `/etc` and `/var` persist.\n\nUsage: bootc &lt;COMMAND&gt;\n\nCommands:\n  upgrade      Download and queue an updated container image to apply\n  switch       Target a new container image reference to boot\n  edit         Apply full changes to the host specification\n  status       Display status\n  usr-overlay  Add a transient writable overlayfs on `/usr` that will be discarded on reboot\n  install      Install the running container to a target\n  help         Print this message or the help of the given subcommand(s)\n\nOptions:\n  -h, --help   Print help (see a summary with '-h')\n</code></pre> <p>Note that among the options we have the upgrade option that we will be using in this use case. The upgrade option allows checking, fetching and using any updated container image corresponding to the imagename:tag we used, in this case quay.io/YOURQUAYUSERNAME/rhel-bootc-vm:httpd</p> <p>The upgrade command requires higher privileges to run, let's perform the upgrade!</p> <pre><code>[bootc-user@localhost ~]$ sudo bootc upgrade\nlayers already present: 71; layers needed: 4 (99.3 MB)\n 379 B [\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588] (0s) Fetched layer sha256:3851db6a0d50                                                                                                                                                                                                                                                                                                                                            Queued for next boot: quay.io/kubealex/rhel-bootc-vm:httpd\n  Version: 9.20240714.0\n  Digest: sha256:09ceaf9cc673ddd49ca204216433c688b09418e24992492b7f0e46ef27f4d5a5\nTotal new layers: 75    Size: 1.3 GB\nRemoved layers:   1     Size: 403 bytes\nAdded layers:     4     Size: 99.3 MB\n</code></pre> <p>As you can see, at the beginning it performs a comparison between the actual rpm-ostree image that the system is booted from and the new image, fetching only the additional layer corresponding to the updates introduced during the last build.</p> <p>Verify that mariadb is still not present at this time, and proceed with a reboot:</p> <pre><code>[bootc-user@localhost ~]$ systemctl status mariadb\nUnit mariadb.service could not be found.\n[bootc-user@localhost ~]$ sudo reboot\n</code></pre> <p>Let's log back in!</p> <pre><code> ~ \u2593\u2592\u2591 ssh bootc-user@192.168.124.16\nbootc-user@192.168.124.16's password: \nThis is a RHEL VM installed using a bootable container as an rpm-ostree source!\nThis server now supports MariaDB as a database, after last update\nLast login: Mon Jul 29 12:10:44 2024 from 192.168.124.1\n[bootc-user@localhost ~]$\n</code></pre> <p>You can already see that something changed, we have a new line in our message of the day, let's see if mariadb is running and test it using the default root user that is created by default (using sudo!):</p> <pre><code>[bootc-user@localhost ~]$ systemctl status mariadb\n\u25cf mariadb.service - MariaDB 10.5 database server\n     Loaded: loaded (/usr/lib/systemd/system/mariadb.service; enabled; preset: disabled)\n     Active: active (running) since Mon 2024-07-29 12:12:27 CEST; 44s ago\n       Docs: man:mariadbd(8)\n             https://mariadb.com/kb/en/library/systemd/\n    Process: 676 ExecStartPre=/usr/libexec/mariadb-check-socket (code=exited, status=0/SUCCESS)\n    Process: 722 ExecStartPre=/usr/libexec/mariadb-prepare-db-dir mariadb.service (code=exited, status=0/SUCCESS)\n    Process: 1373 ExecStartPost=/usr/libexec/mariadb-check-upgrade (code=exited, status=0/SUCCESS)\n   Main PID: 1359 (mariadbd)\n     Status: \"Taking your SQL requests now...\"\n      Tasks: 13 (limit: 23136)\n     Memory: 97.1M\n        CPU: 195ms\n     CGroup: /system.slice/mariadb.service\n             \u2514\u25001359 /usr/libexec/mariadbd --basedir=/usr\n\nJul 29 12:12:27 localhost.localdomain mariadb-prepare-db-dir[1315]: The second is mysql@localhost, it has no password either, but\nJul 29 12:12:27 localhost.localdomain mariadb-prepare-db-dir[1315]: you need to be the system 'mysql' user to connect.\nJul 29 12:12:27 localhost.localdomain mariadb-prepare-db-dir[1315]: After connecting you can set the password, if you would need to be\nJul 29 12:12:27 localhost.localdomain mariadb-prepare-db-dir[1315]: able to connect as any of these users with a password and without sudo\nJul 29 12:12:27 localhost.localdomain mariadb-prepare-db-dir[1315]: See the MariaDB Knowledgebase at https://mariadb.com/kb\nJul 29 12:12:27 localhost.localdomain mariadb-prepare-db-dir[1315]: Please report any problems at https://mariadb.org/jira\nJul 29 12:12:27 localhost.localdomain mariadb-prepare-db-dir[1315]: The latest information about MariaDB is available at https://mariadb.org/.\nJul 29 12:12:27 localhost.localdomain mariadb-prepare-db-dir[1315]: Consider joining MariaDB's strong and vibrant community:\nJul 29 12:12:27 localhost.localdomain mariadb-prepare-db-dir[1315]: https://mariadb.org/get-involved/\nJul 29 12:12:27 localhost.localdomain systemd[1]: Started MariaDB 10.5 database server.\n</code></pre> <pre><code>[bootc-user@localhost ~]$ sudo mysql\nWelcome to the MariaDB monitor.  Commands end with ; or \\g.\nYour MariaDB connection id is 3\nServer version: 10.5.22-MariaDB MariaDB Server\n\nCopyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others.\n\nType 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.\n\nMariaDB [(none)]&gt; \n</code></pre> <p>Here we go, our image is updated and fully working. Of course we can use the new image to provision similar VMs that need the same pieces of software on them.</p>"},{"location":"use-cases/bootc-image-builder-ami/","title":"Use Case - Building a RHEL AWS AMI image using bootc-image-builder","text":"<p>[!WARNING] This example requires an active AWS account. Free tier could not be enough due to the 5GB limitation on S3 storage.</p> <p>In this example, we will build a container image from a Containerfile and we will generate an AWS AMI to use as a base for Instances.</p> <p>The Containerfile in the example:</p> <ul> <li>Updates packages</li> <li>Installs tmux and mkpasswd to create a simple user password</li> <li>Creates a bootc-user user in the image</li> <li>Adds the wheel group to sudoers</li> <li>Installs Apache Server</li> <li>Enables the systemd unit for httpd</li> <li>Adds a custom index.html</li> </ul>"},{"location":"use-cases/bootc-image-builder-ami/#building-the-image","title":"Building the image","text":"<p>Review the Containerfile.ami file, that includes all the building steps for the image.</p> <p>To build the image:</p> <pre><code>podman build -f Containerfile.ami -t rhel-bootc-vm:ami .\n</code></pre>"},{"location":"use-cases/bootc-image-builder-ami/#testing-the-image","title":"Testing the image","text":"<p>You can now test it using:</p> <pre><code>podman run -it --name rhel-bootc-vm --hostname rhel-bootc-vm -p 8080:80 rhel-bootc-vm:ami\n</code></pre> <p>Note: The \"-p 8080:80\" part forwards the container's http port to the port 8080 on the host to test that it is working.</p> <p>The container will now start and a login prompt will appear:</p> <p></p> <p>On another terminal tab or in your browser, you can verify that the httpd server is working and serving traffic.</p> <p>Terminal</p> <pre><code> ~ \u2593\u2592\u2591 curl localhost:8080\nWelcome to the bootc-http instance!\n</code></pre> <p>Browser</p> <p></p>"},{"location":"use-cases/bootc-image-builder-ami/#tagging-and-pushing-the-image","title":"Tagging and pushing the image","text":"<p>To tag and push the image you can simply run (replace YOURQUAYUSERNAME with the account name):</p> <pre><code>export QUAY_USER=YOURQUAYUSERNAME\n</code></pre> <pre><code>podman tag rhel-bootc-vm:ami quay.io/$QUAY_USER/rhel-bootc-vm:ami\n</code></pre> <p>Log-in to Quay.io:</p> <pre><code>podman login -u $QUAY_USER quay.io\n</code></pre> <p>And push the image:</p> <pre><code>podman push quay.io/$QUAY_USER/rhel-bootc-vm:ami\n</code></pre> <p>You can now browse to https://quay.io/repository/YOURQUAYUSERNAME/rhel-bootc-vm?tab=settings and ensure that the repository is set to \"Public\".</p> <p></p>"},{"location":"use-cases/bootc-image-builder-ami/#configure-required-resources-for-aws","title":"Configure required resources for AWS","text":"<p>The AMI building process will need some configuration both on the client (for CLI configuration and credentials) and on AWS (for resources and IAM).</p> <p>The specific needs are:</p> <ul> <li>an S3 bucket to temporarily store the AMI image that will be imported in the catalog</li> <li>a policy (vmimport) to allow importing from S3 to the AMI catalog</li> <li>a role to allow the vmie service and bind the policy</li> </ul> <p>In this folder you can preview the policy definition and the role definition before applying.</p> <p>To configure use the aws configure command and provide the required information:</p> <pre><code>[~]$ aws configure \nAWS Access Key ID []: \nAWS Secret Access Key []: \nDefault region name []: \nDefault output format [json]:\n</code></pre> <p>Once this is in place, we can proceed with the resources.</p> <p>For S3 (replace YOURREGION with the correct region, ie. eu-west-1):</p> <p>[!TIP] S3 Bucket names are globally registered and unique, based on the name you find available, edit the reference in lines 12-13 of the policy file</p> <pre><code>[~]$ export REGION=YOURREGION\naws s3api create-bucket --bucket rhel-bootc-demo --create-bucket-configuration LocationConstraint=$REGION\n</code></pre> <p>Let's proceed with the role:</p> <pre><code>aws iam create-role --role-name vmimport --assume-role-policy-document file://files/aws-role.json \n</code></pre> <p>And then associate the policy to the role:</p> <pre><code>aws iam put-role-policy --role-name vmimport --policy-name vmimport --policy-document file://files/aws-policy.json\n</code></pre> <p>We are now good to go!</p>"},{"location":"use-cases/bootc-image-builder-ami/#generating-the-aws-ami-image","title":"Generating the AWS AMI image","text":"<p>To generate the AMI image we will be using bootc-image-builder container image that will help us transitioning from our newly generated bootable container image to an AMI image that can be used on AWS.</p> <p>Let's proceed with the QCOW image creation:</p> <pre><code>sudo podman run \\\n    --rm \\\n    -it \\\n    --privileged \\\n    --pull=newer \\\n    -v $HOME/.aws:/root/.aws:ro \\\n    --env AWS_PROFILE=default \\\n    registry.redhat.io/rhel9/bootc-image-builder:latest \\\n    --type ami \\\n    --aws-ami-name rhel-bootc-x86 \\\n    --aws-bucket rhel-bootc-demo \\\n    --aws-region eu-west-1 \\\n    quay.io/$QUAY_USER/rhel-bootc-vm:ami\n</code></pre> <p>The process will take care of all required steps (deploying the image, SELinux configuration, filesystem configuration, ostree configuration, etc.), after a couple of minutes we will find in the output:</p> <pre><code>Building manifest-ami.json\nstarting -Pipeline source org.osbuild.containers-storage: 6ec72d5cb7fb74985ee0fcdc8d90db85079cd08caa64fde9153c40aae3744f18\nBuild\n  root: &lt;host&gt;\nPipeline build: 733863e98e5497425dbf00ac2eec52175d453834f17868944ed3408bcd9a3d16\nBuild\n  root: &lt;host&gt;\n  runner: org.osbuild.rhel82 (org.osbuild.rhel82)\n[...]\n\n\u23f1  Duration: 1s\nmanifest - finished successfully\nbuild:          733863e98e5497425dbf00ac2eec52175d453834f17868944ed3408bcd9a3d16\nimage:          6b2f313ea4e75ddb9f8c9f2da14d4234760986240d1957093bb3631f0010c09e\nqcow2:          194f4993f08ada94b56bc5a59d17a08251388f9210e13f4671d231f7cd9abb97\nvmdk:           6d03b4759af85fd6408f36c72fde3eaa271466beef14a5f1af0499410055df9c\novf:            c2410b0f4eecb91c7298d17c98dc672b42aedd02bb9809dab8feb1b185259689\narchive:        950f23c305d2b41148790246e9abb8c925da34077f2954fabad284b9782f914e\nBuild complete!\nUploading image/disk.raw to rhel-bootc-demo:b1a83f25-051e-434c-a50f-ab634d1b798c-disk.raw\n10.00 GiB / 10.00 GiB [------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------] 100.00% 79.03 MiB p/s\nFile uploaded to https://rhel-bootc-demo.s3.eu-west-1.amazonaws.com/b1a83f25-051e-434c-a50f-ab634d1b798c-disk.raw\nRegistering AMI rhel-bootc-x86\nDeleted S3 object rhel-bootc-demo:b1a83f25-051e-434c-a50f-ab634d1b798c-disk.raw\nAMI registered: ami-0ade40e197a89bb69\nSnapshot ID: snap-068821f35b9b832af\n</code></pre> <p>You can verify that the AMI is now present in the AMIs section on AWS. (the URL may be different based on the region).</p> <p></p>"},{"location":"use-cases/bootc-image-builder-ami/#create-the-instance-on-aws","title":"Create the Instance on AWS","text":"<p>Using your preferred method, either via GUI or CLI, you can now create a fresh instance using the AMI we just imported.</p> <p>Wait for the Instance to be ready and retrieve the IP address to log-in using SSH using bootc-user/redhat credentials:</p> <pre><code> ~ \u2593\u2592\u2591 \n\u276f ssh bootc-user@*****\n\nThe authenticity of host '***** (*****)' can't be established.\nED25519 key fingerprint is SHA256:OgY5Ym9dycIE2KPS5SRYRcmogUHalrUD35CyEH2A/j4.\nThis key is not known by any other names.\nAre you sure you want to continue connecting (yes/no/[fingerprint])? yes\nWarning: Permanently added '*****' (ED25519) to the list of known hosts.\nbootc-user@*****'s password: \n[bootc-user@ip-172-31-22-31 ~]$ \n</code></pre>"},{"location":"use-cases/bootc-image-builder-iso/","title":"Use Case - Building a RHEL ISO image using bootc-image-builder","text":"<p>In this example, we will build a container image from a Containerfile and we will generate a ISO image to spin up a Virtual Machine in KVM and install RHEL from the container image.</p> <p>The Containerfile in the example:</p> <ul> <li>Updates packages</li> <li>Installs tmux and mkpasswd to create a simple user password</li> <li>Creates a bootc-user user in the image</li> <li>Adds the wheel group to sudoers</li> <li>Installs Apache Server</li> <li>Enables the systemd unit for httpd</li> <li>Adds a custom index.html</li> </ul>"},{"location":"use-cases/bootc-image-builder-iso/#building-the-image","title":"Building the image","text":"<p>Review the Containerfile.iso file, that includes all the building steps for the image.</p> <p>To build the image:</p> <pre><code>podman build -f Containerfile.iso -t rhel-bootc-vm:iso .\n</code></pre>"},{"location":"use-cases/bootc-image-builder-iso/#testing-the-image","title":"Testing the image","text":"<p>You can now test it using:</p> <pre><code>podman run -it --name rhel-bootc-vm --hostname rhel-bootc-vm -p 8080:80 rhel-bootc-vm:iso\n</code></pre> <p>Note: The \"-p 8080:80\" part forwards the container's http port to the port 8080 on the host to test that it is working.</p> <p>The container will now start and a login prompt will appear:</p> <p></p> <p>On another terminal tab or in your browser, you can verify that the httpd server is working and serving traffic.</p> <p>Terminal</p> <pre><code> ~ \u2593\u2592\u2591 curl localhost:8080\nWelcome to the bootc-http instance!\n</code></pre> <p>Browser</p> <p></p>"},{"location":"use-cases/bootc-image-builder-iso/#tagging-and-pushing-the-image","title":"Tagging and pushing the image","text":"<p>To tag and push the image you can simply run (replace YOURQUAYUSERNAME with the account name):</p> <pre><code>export QUAY_USER=YOURQUAYUSERNAME\n</code></pre> <pre><code>podman tag rhel-bootc-vm:httpd quay.io/$QUAY_USER/rhel-bootc-vm:iso\n</code></pre> <p>Log-in to Quay.io:</p> <pre><code>podman login -u $QUAY_USER quay.io\n</code></pre> <p>And push the image:</p> <pre><code>podman push quay.io/$QUAY_USER/rhel-bootc-vm:iso\n</code></pre>"},{"location":"use-cases/bootc-image-builder-iso/#customize-the-image","title":"Customize the image","text":"<p>In this example, we will not create the user in the image, but we will provide a customization using the config.toml file. It can be used to perform customizations of users, groups, etc.</p> <p>A sample config.toml that we will use to create our bootc-user/redhat and add it to the wheel group is as follows:</p> <pre><code>[[blueprint.customizations.user]]\nname = \"bootc-user\"\npassword = \"redhat\"\ngroups = [\"wheel\"]\n</code></pre> <p>In the directory, a config.toml file is already present.</p>"},{"location":"use-cases/bootc-image-builder-iso/#generating-the-iso-image","title":"Generating the ISO image","text":"<p>To generate the ISO image we will be using bootc-image-builder container image that will help us transitioning from our newly generated bootable container image to a ISO file that can be used with KVM to install the OS.</p> <p>The bootc-image-builder container will need rootful access to run, let's proceed with the ISO image creation:</p> <pre><code>sudo podman run \\\n    --rm \\\n    -it \\\n    --privileged \\\n    --pull=newer \\\n    --security-opt label=type:unconfined_t \\\n    -v $(pwd)/output:/output \\\n    -v /var/lib/containers/storage:/var/lib/containers/storage \\\n    registry.redhat.io/rhel9/bootc-image-builder:latest \\\n    --type iso \\\n    --local \\\n    quay.io/$QUAY_USER/rhel-bootc-vm:iso\n</code></pre> <p>We will use the image we pushed before to create our image in the output folder.</p> <p>The process will take care of all required steps (deploying the image, SELinux configuration, filesystem configuration, ostree configuration, etc.), after a couple of minutes we will find in the output:</p> <pre><code>Generating manifest manifest-iso.json\nDONE\nBuilding manifest-iso.json\nstarting -Pipeline source org.osbuild.containers-storage: f1027594ecbee0b434f86af01d4ba21b478265c0c773e35c387858d0fc4bf16d\nBuild\n  root: &lt;host&gt;\nPipeline source org.osbuild.curl: 07337b98b3c859adfb37b011d83cf0511884147bf999e7869ffbf9074b529a4f\nBuild\n  root: &lt;host&gt;\n[...]\n\n\u23f1  Duration: 9s\norg.osbuild.implantisomd5: 3798a4bfccd982e2e24d6130c4174eba98ad12f94a41b25ec8884a8cfccaf8ce {\n  \"filename\": \"install.iso\"\n}\n['implantisomd5', '/run/osbuild/tree/install.iso']\nInserting md5sum into iso image...\nmd5 = 66adac8cb9127c31942085bade81a8d4\nInserting fragment md5sums into iso image...\nfragmd5 = 9d5d936a1b5c8f9bf96e1e14c164898d8e2fcf45652dbee6f3741e17b5ca\nfrags = 20\nSetting supported flag to 0\n\n\u23f1  Duration: 6s\nmanifest - finished successfully\nbuild:          9133fb8610ab053dae7e281e6a6655dbb912c4530d32e4da75c06b8713a87c80\nanaconda-tree:  fcd61d1236a42900977530f12f45fe452f2f0c8bf3c80a7ba60cb45ffe4bf36d\nrootfs-image:   0a517e05ab42f947beec8dae4d2da338ca9cc7fe17b1daba013e24b1c60aeadf\nefiboot-tree:   61a20c820b40436ce7bd6d1a74c6b97a05f7c8800b678083942e814cf9f7cc0e\nbootiso-tree:   fd0185a1c0eb53df152acd85195c016315e79dd5dc32eb32d07abf0e21251c62\nbootiso:        3798a4bfccd982e2e24d6130c4174eba98ad12f94a41b25ec8884a8cfccaf8ce\nBuild complete!\nResults saved in\n</code></pre> <p>Verify that under the output/bootiso folder we have our image ready to be used.</p> <pre><code> ~/ \u2593\u2592\u2591 tree output\noutput/\n\u251c\u2500\u2500 bootiso\n\u2502   \u2514\u2500\u2500 install.iso\n\u2514\u2500\u2500 manifest-iso.json\n</code></pre>"},{"location":"use-cases/bootc-image-builder-iso/#create-the-vm-in-kvm","title":"Create the VM in KVM","text":"<p>We will now use the image to spin up our Virtual Machine in KVM.</p> <pre><code>sudo virt-install \\\n    --name rhel-bootc-vm \\\n    --vcpus 4 \\\n    --memory 4096 \\\n    --cdrom ./output/bootiso/install.iso \\\n    --os-variant rhel9.4 \\\n    --disk size=20 \\\n    --network network=default\n</code></pre> <p>We can check that the installer is running using the VM Console:</p> <p></p> <p>Wait for the VM to be ready and retrieve the IP address for the domain to log-in using SSH using bootc-user/redhat credentials:</p> <pre><code> ~ \u2593\u2592\u2591 VM_IP=$(sudo virsh -q domifaddr rhel-bootc-vm | awk '{ print $4 }' | cut -d\"/\" -f1) &amp;&amp; ssh bootc-user@$VM_IP\nWarning: Permanently added '192.168.124.209' (ED25519) to the list of known hosts.\nbootc-user@192.168.124.209's password: \nThis is a RHEL 9.4 VM installed using a bootable container as an rpm-ostree source!\n[bootc-user@localhost ~]$ \n</code></pre>"},{"location":"use-cases/bootc-image-builder-qcow/","title":"Use Case - Building a RHEL QCOW image using bootc-image-builder","text":"<p>In this example, we will build a container image from a Containerfile and we will generate a QCOW image to spin up a Virtual Machine in KVM.</p> <p>The Containerfile in the example:</p> <ul> <li>Updates packages</li> <li>Installs tmux and mkpasswd to create a simple user password</li> <li>Creates a bootc-user user in the image</li> <li>Adds the wheel group to sudoers</li> <li>Installs Apache Server</li> <li>Enables the systemd unit for httpd</li> <li>Adds a custom index.html</li> </ul>"},{"location":"use-cases/bootc-image-builder-qcow/#building-the-image","title":"Building the image","text":"<p>Review the Containerfile.qcow file, that includes all the building steps for the image.</p> <p>To build the image:</p> <pre><code>podman build -f Containerfile.qcow -t rhel-bootc-vm:qcow .\n</code></pre>"},{"location":"use-cases/bootc-image-builder-qcow/#testing-the-image","title":"Testing the image","text":"<p>You can now test it using:</p> <pre><code>podman run -it --name rhel-bootc-vm --hostname rhel-bootc-vm -p 8080:80 rhel-bootc-vm:qcow\n</code></pre> <p>Note: The \"-p 8080:80\" part forwards the container's http port to the port 8080 on the host to test that it is working.</p> <p>The container will now start and a login prompt will appear:</p> <p></p> <p>On another terminal tab or in your browser, you can verify that the httpd server is working and serving traffic.</p> <p>Terminal</p> <pre><code> ~ \u2593\u2592\u2591 curl localhost:8080\nWelcome to the bootc-http instance!\n</code></pre> <p>Browser</p> <p></p>"},{"location":"use-cases/bootc-image-builder-qcow/#generating-the-qcow-image","title":"Generating the QCOW image","text":"<p>To generate the QCOW image we will be using bootc-image-builder container image that will help us transitioning from our newly generated bootable container image to a VM image that can be used with KVM.</p> <p>The bootc-image-builder container will need rootful access to run, so the first thing we need to do is copying the image from our current user (the one we built the image with) to root:</p> <pre><code>podman image scp $(whoami)@localhost::rhel-bootc-vm:qcow\n</code></pre> <p>Now, verify that the image is correctly present for root user:</p> <pre><code> ~ \u2593\u2592\u2591 sudo podman images\nREPOSITORY                                TAG         IMAGE ID      CREATED        SIZE\nlocalhost/rhel-bootc-vm                 qcow        0ee1017eb9bc  7 minutes ago  1.81 GB\n</code></pre> <p>We are now ready! Let's proceed with the QCOW image creation:</p> <pre><code>sudo podman run \\\n    --rm \\\n    -it \\\n    --privileged \\\n    --pull=newer \\\n    --security-opt label=type:unconfined_t \\\n    -v $(pwd)/output:/output \\\n    -v /var/lib/containers/storage:/var/lib/containers/storage \\\n    registry.redhat.io/rhel9/bootc-image-builder:latest \\\n    --type qcow2 \\\n    --local \\\n    localhost/rhel-bootc-vm:qcow\n</code></pre> <p>We will use the local image we just copied to save in the output folder our generated image.</p> <p>The process will take care of all required steps (deploying the image, SELinux configuration, filesystem configuration, ostree configuration, etc.), after a couple of minutes we will find in the output:</p> <pre><code>Generating manifest-qcow2.json ... DONE\nBuilding manifest-qcow2.json\nstarting -Pipeline source org.osbuild.containers-storage: 8aaabad5f0c2c00eb12666076be4e6843f04e262230e2976dbb1218e96f2ca53\nBuild\n  root: &lt;host&gt;\nPipeline build: 2fb8b2a9ec9dc564950ddc6213d923bdd036c2328a97d0bb785c72fb5b6e1154\nBuild\n  root: &lt;host&gt;\n  runner: org.osbuild.rhel82 (org.osbuild.rhel82)\n[...]\n\n\u23f1  Duration: 81s\nmanifest - finished successfully\nbuild:          2fb8b2a9ec9dc564950ddc6213d923bdd036c2328a97d0bb785c72fb5b6e1154\nimage:          a578f97344212ef8cdc1a53717b61d72b4cc89504811c7b73e35aafe9a4011e5\nqcow2:          ae3acbc9afa8886b03ce112d57177e7a9e0a05819d3f0d7bba9fc0e2663fddf5\nvmdk:           a926054ee74e3fa6193efc467be82ad7ff041e58db6712cabf19a82793cbc345\novf:            02baf8c99f0322217499ddf7ca5f853b74f37926ab7739efc2e7e6dd87ecc8c1\narchive:        beb1ba4cddc9a18f49f190d33d9a3ef0221b90d19683f810f170ec4629c55f39\nBuild complete!\n</code></pre> <p>Verify that under the output/qcow2 folder we have our image ready to be used.</p> <pre><code> ~/ \u2593\u2592\u2591 tree output\noutput\n\u251c\u2500\u2500 manifest-qcow2.json\n\u2514\u2500\u2500 qcow2\n    \u2514\u2500\u2500 disk.qcow2\n</code></pre>"},{"location":"use-cases/bootc-image-builder-qcow/#create-the-vm-in-kvm","title":"Create the VM in KVM","text":"<p>We will now use the image to spin up our Virtual Machine in KVM.</p> <pre><code>sudo virt-install \\\n    --name rhel-bootc-vm \\\n    --vcpus 4 \\\n    --memory 4096 \\\n    --import --disk ./output/qcow2/disk.qcow2,format=qcow2 \\\n    --os-variant rhel9.4 \\\n    --network network=default\n</code></pre> <p>Wait for the VM to be ready and retrieve the IP address for the domain to log-in using SSH using bootc-user/redhat credentials:</p> <pre><code> ~ \u2593\u2592\u2591 VM_IP=$(sudo virsh -q domifaddr rhel-bootc-vm | awk '{ print $4 }' | cut -d\"/\" -f1) &amp;&amp; ssh bootc-user@$VM_IP\nWarning: Permanently added '192.168.150.157' (ED25519) to the list of known hosts.\nbootc-user@192.168.150.157's password:\n[bootc-user@localhost ~]$ curl localhost\nWelcome to the bootc-http instance!\n[bootc-user@localhost ~]$\n</code></pre>"}]}